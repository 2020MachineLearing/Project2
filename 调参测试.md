## 初始参数

    'maxlen':40, # maximum utterance length
    'diaglen':10, # how many utterance kept in the context window
    # Model Arguments
    'emb_size':200, # size of word embeddings
    'rnn_hid_utt':512, # number of rnn hidden units for utterance encoder
    'rnn_hid_ctx':512, # number of rnn hidden units for context encoder
    'rnn_hid_dec':512, # number of rnn hidden units for decoder
    'n_layers':1, # number of layers
    'dropout':0.5, # dropout applied to layers (0 = no dropout)
    'teach_force': 0.8, # use teach force for decoder
      
    # Training Arguments
    'batch_size':64,
    'epochs':10, # maximum number of epochs
    'lr':2e-4, # autoencoder learning rate
    'beta1':0.9, # beta1 for adam
    'init_w':0.05, # initial w
    'clip':5.0,  # gradient clipping, max norm  
## 初始结果

```
'avg_len': 8.609278144371126 #平均样本句子长度
'recall_bleu': 0.28516362689702557
'prec_bleu': 0.28516362689702557
'f1_bleu': 0.28516362689202557
'time_consumed':933.6945259571075 #训练模型所用的时间，包括数据载入时间，单位为s
```

经过对初始模型的训练，我们发现，现有的RNN模型中有关blue的参数都相等，因此统一使用bleu代替。

## 参数说明

### bleu

**经过查阅，Bleu参数的含义如下：**

Wikipedia https://en.wikipedia.org/wiki/BLEU

**BLEU** (**bilingual evaluation understudy**) is an algorithm for [evaluating](https://en.wikipedia.org/wiki/Evaluation_of_machine_translation) the quality of text which has been [machine-translated](https://en.wikipedia.org/wiki/Machine_translation) from one [natural language](https://en.wikipedia.org/wiki/Natural_language) to another. Quality is considered to be the correspondence between a machine's output and that of a human: "the closer a machine translation is to a professional human translation, the better it is" – this is the central idea behind BLEU.[[1\]](https://en.wikipedia.org/wiki/BLEU#endnote_Papineni2002a) BLEU was one of the first [metrics](https://en.wikipedia.org/wiki/Metric_(mathematics)) to claim a high [correlation](https://en.wikipedia.org/wiki/Correlation) with human judgements of quality,[[2\]](https://en.wikipedia.org/wiki/BLEU#endnote_Papineni2002a)[[3\]](https://en.wikipedia.org/wiki/BLEU#endnote_Coughlin2003a) and remains one of the most popular automated and inexpensive metrics.

Scores are calculated for individual translated segments—generally sentences—by comparing them with a set of good quality reference translations. Those scores are then averaged over the whole [corpus](https://en.wikipedia.org/wiki/Text_corpus) to reach an estimate of the translation's overall quality. Intelligibility or grammatical correctness are not taken into account[*[citation needed](https://en.wikipedia.org/wiki/Wikipedia:Citation_needed)*].

BLEU's output is always a number between 0 and 1. This value indicates how similar the candidate text is to the reference texts, with values closer to 1 representing more similar texts. Few human translations will attain a score of 1, since this would indicate that the candidate is identical to one of the reference translations. For this reason, it is not necessary to attain a score of 1. Because there are more opportunities to match, adding additional reference translations will increase the BLEU score.

zhihu https://zhuanlan.zhihu.com/p/39100621

BLEU指标的范围从0到1。 除非翻译与参考翻译完全相同，否则很少有翻译获得1分。 因此，即使是人工翻译也不一定得1分。 值得注意的是，每个句子的参考翻译越多，得分就越高。 因此，必须谨慎对待具有不同参考翻译数量的评估进行“粗略”比较：在大约500个句子的测试语料库（40个一般新闻故事）中，人工翻译对四个参考文献得分为0.3468，对两个参考文献得分为0.2571 。 表1显示了5个系统的在该测试语料库中对两个参考翻译的BLEU得分。

### dialoglen：

dialoglen的长度为训练时选择的context的单词个数

### dropout：

zhihu (https://zhuanlan.zhihu.com/p/38200980)

Dropout可以作为训练深度神经网络的一种trick供选择。在每个训练批次中，通过忽略一半的特征检测器（让一半的隐层节点值为0），可以明显地减少过拟合现象。这种方式可以减少特征检测器（隐层节点）间的相互作用，检测器相互作用是指某些检测器依赖其他检测器才能发挥作用。

Dropout说的简单一点就是：我们在前向传播的时候，让某个神经元的激活值以一定的概率p停止工作，这样可以使模型泛化性更强，因为它不会太依赖某些局部的特征，如图1所示。

当前Dropout被大量利用于全连接网络，而且一般认为设置为0.5或者0.3，而在卷积网络隐藏层中由于卷积自身的稀疏化以及稀疏化的ReLu函数的大量使用等原因，Dropout策略在卷积网络隐藏层中使用较少。总体而言，Dropout是一个超参，需要根据具体的网络、具体的应用领域进行尝试。



## 参数调整

### 调整dialoglen:

**预测结果：**

随着dialoglen的增大，bleu应该先会逐步增大，直到到达一个阈值会趋近于平衡。原因是当context的长度过短时，模型训练由于可用的语境太短训练效果并不好。但是由于平均对话长度的限制，当选择的context长度超过对话长度时，bleu就不再增大。

而随着dialog的增大，time_consmed应该增大，因为随着context的增大，训练模型的复杂度会增加，训练时间变长

| dialoglen | bleu                | Time_consumed     |
| --------- | ------------------- | ----------------- |
| 1 | 0.28404174237724883 | 696.8668274879456 |
| 2         | 0.28890403493056077 | 783.555210351944  |
| 4         | 0.2836057378572623 | 856.6012506484985 |
| 6         | 0.2831718109451517  | 885.6468575000763 |
| 8         | 0.28525902026047817 | 908.295951128006  |
| 10        | 0.28516362689702557 | 933.6945259571075 |
| 12        | 0.28724633500078595 | 961.2398629188538 |
| 14        | 0.28382962920341287 | 990.7178490161896 |
| 16        | 0.2817584768940273 | 994.738960981369 |
| 18        | 0.28497252504947096 | 1029.0544159412384 |
| 20 | 0.2831658738318325 | 1037.3628072738647 |


    start = time.time()
    model = train(args)
    end = time.time()
    print("time consumed:",end-start)
经过观察，我们发现训练模型的时间确实如预料的一样，随着context长度的增长而增长。但是bleu却没有明显的变化，一直在来回波动，甚至context为2的时候最高。我个人认为是因为训练样本和测试样本的平均长度都在8左右，这样训练出的模型不太需要考虑太靠前的context，所以context长度的选取对结果没有什么影响。

### 调整dropout：

**预测结果**

一开始dropout较小时，可能存在过拟合现象，得分可能偏低。随着dropout增大，得分逐渐升高，等到dropout过大时，结果越来越趋近于随机。过多神经元被屏蔽后，会使得训练效果也不太理想。

而训练时间应该没有什么变化。

| dropout | bleu                | Time_consumed     |
| ------- | ------------------- | ----------------- |
| 0.0     | 0.2698249595246275  | 942.4414939880371 |
| 0.1     | 0.2795380746313778  | 941.5187513828278 |
| 0.2     | 0.2767228232340068  | 948.4406220912933 |
| 0.3     | 0.27648717483607055 | 991.0391957759857 |
| 0.4     | 0.2797996015556291  | 935.3210241794586 |
| 0.5     | 0.28516362689202557 | 933.6945259571075 |
| 0.6     | 0.2821479175978641  | 983.2623007297516 |
| 0.7     | 0.28241926574638915 | 929.4391362667084 |
| 0.8     | 0.2778827897623312  | 933.2382998466492 |
| 0.9     | 0.27287787203826674 | 1083.509421825409 |
| 1.0     | 0.2727277000152507  | 984.1578514575958 |

观察数据，发现模型训练时间在不同的dropout下都差不多，与预测的结果相同。而bleu，在dropout较小的时候较低，应该发生了预测中的过拟合现象，随着dropout的提高，bleu逐渐上升，在drop = 0.5时，bleu到达峰值，之后慢慢下降。可以发现一开始的模型给出的dropout = 0.5已经是一个调的很好的参数了。

